{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "\n",
    "from model import GPTConfig, GPT, new_gelu\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 16 21:24:59 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050         On | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P8               N/A /  N/A|   2121MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2173      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      3012      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A     34700      C   .../versions/3.8.5/envs/eda/bin/python     2110MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar modelo pre-entrenado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "out_dir = 'out/extended_by_char_out-reddit-fix'\n",
    "start = ''\n",
    "num_samples = 10\n",
    "max_new_tokens = 500\n",
    "temperature = 0.9\n",
    "#top_k = 200\n",
    "seed = 33313988\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device='cpu'\n",
    "print('Using device:', device)\n",
    "dtype='float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device_type='cpu'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar configuraciones del checkpoint e inicializarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.62M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la configuraci√≥n del √∫ltimo checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTConfig(block_size=256, vocab_size=656, n_layer=6, n_head=6, n_embd=384, dropout=0.2, bias=False)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptconf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitectura del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_embedding_table): Embedding(656, 384)\n",
       "  (position_embedding_table): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffwd): FeedForward(\n",
       "        (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "        (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffwd): FeedForward(\n",
       "        (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "        (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffwd): FeedForward(\n",
       "        (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "        (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffwd): FeedForward(\n",
       "        (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "        (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffwd): FeedForward(\n",
       "        (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "        (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm()\n",
       "      (ffwd): FeedForward(\n",
       "        (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "        (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm()\n",
       "  (lm_head): Linear(in_features=384, out_features=656, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√∫mero de par√°metros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de par√°metros GPT-sentiment checkpoint: 10.62 millones\n"
     ]
    }
   ],
   "source": [
    "print(f\"N√∫mero de par√°metros GPT-sentiment checkpoint: {model.get_num_params()/1e6:.2f} millones\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar tokenizador y crear funciones `encode` y `decode`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with open('./data/extended_by_char/meta.pkl', 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "    vocab_size = meta['vocab_size']\n",
    "    itos = meta['itos']\n",
    "    stoi = meta['stoi']\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generaci√≥n de muestras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear una funci√≥n para generar muestras y concatenarlas.\n",
    "\n",
    "Esta funci√≥n se utiliza en `train.py` para capturar samples en \n",
    "cada loop de evaluaci√≥n del modelo. La idea es ver como evoluciona\n",
    "la generaci√≥n de texto durante el entrenamiento, y complementar la\n",
    "informaci√≥n de la funci√≥n de perdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_samples(num_samples, max_new_tokens=10, temperature=1.0):\n",
    "    model.eval()\n",
    "    out = []\n",
    "    for k in range(num_samples):\n",
    "            y = model.generate(idx=torch.zeros((1, gptconf.block_size), dtype=torch.long, device=device), max_new_tokens=max_new_tokens, temperature=temperature)\n",
    "            out.append(f\"({k+1}) {decode(y[0][gptconf.block_size:].tolist())}\")\n",
    "    model.train()\n",
    "    return '\\n\\n'.join(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunas muestras generadas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1)  ùêåùêöùê•ùê•ùê•ùê•ùêöùêûùó≤üåñüåïüî≠ùêûùêõüåïüëàùê•ùêûüß≤üíû‚Äºü•∑ü•∑ùêßü•∑Ï†Ñùó•ùóîùó¢ ùóóùóµ‚ò†ÏôÄùêõüåïüòÑüòÑüåûùêöüåàüÜòüòùüòùüòùùêÉÏ†ÑÏ†Ñüåëùóúùó°ùóî‚Äºüá®Í∞ú Contea \n",
      "\n",
      "\n",
      "Dios de sufturo, aprendimiento, obtenido el poder de este pa√≠s chileno, compuesto a donde la comunidad le ha empiezado en ser tan inmoral de odiano en el humanidad, impunidades y volu\n",
      "\n",
      "(2) üì£üó≥üá®üá±üåéùó®Ï†Ñüåïüåû√öùóπùê•ùêÉùó®ü•∑üé™üá®üá±üá®üá±üá®üá±üá®üåæ‚ÄºÔ∏èCon√°n el Eliminado‚Äù, pobre eso - https: le damos problema que si en una se√±al del de ni√±os. \n",
      "üö© ‚¨áÔ∏è     üî¥üóΩüíûLa \"no sea educaci√≥n de un problema es la UP, sino que se quiere un problema de Omingo, lo hace \"al voto y endio\" \"no p\n",
      "\n",
      "(3) ùê•üî≠üåûùê•Ï†Ñüî≠üë®üåàü§™ ùóóùóòü•∑ü•∑üåóüôãüåòüåëüåïüî≠üî≠‚ù§ü•∑üî≠Aptate | @user \n",
      "\n",
      "#Renador_Ìä∏üåòü™ìùêûÏ†Ñùó≠‚ò∫ùêÉùêöùêûüåûüåïùó¶üü¢üü¢üü£   üá®üá±üßôüì∏ùê•ùêûùê≠‚è¨ùê•ùêõùó∞üåû‚òÑüé™üåû√¶ùê®Ìã¥üëé@user Yudato rump, clancame√±os de completa crimen de acuerdo con fascismo entre 50. Los derechos de los regreses de reclamos por el igualdad comunista traidor gas\n",
      "\n",
      "(4) üôãùóòùêèùó≠üåéüíÖ‚Äçüåòùó∞‚òÑùó¢:&ùóóùóòùóüùóó‚ú®üòÉüü£ùó•ùó¶ùó®ùóò]‚Å©üî≠] üáµùê¢ùêöùêöüìªùê•ùêöùê•ùêöùê®ùó¶üî≠üî≠‚Äôüåëùó≠ùóîüåûüò≠Buco cam: ¬ª\n",
      " Comunica en https: Conflictor ‚ùóÔ∏è [fue] üîóüü£ü•∑ùê≠ùêöü•Çü•¨üü£ En ùóñÏ†ÑÍ≥°ùó≠ùó≠ùê•ùê•ùê•ùêûùêöùê•ùê•ùó≤ùó∞Ïù¥ùóµüåûüç∫ùê•ùê•ùêûüåñùêûùê®ùêûùêöüíóüíóùê¢ùóπùê•ùê•ùêûüåñüåïùê®„Äãùó®Ï†ÑüöÄüëßùêöùê•ùêûüåñüåûüåûü•∑ü•∑ü•∑ùêöüë∑üßôüèºü§ûüè´ü•∑ü•∑ùê¢ùêßùêöüèÜ ùêèùêßùê≠ùê≠ùêöùêöüíìüî≠üåûüòàüîñùê•üßôÔ∏èùê¢ùê¢ùêûùêöüåï√¨üåïùêöùêßùêúùêùùêûùê≠ùêöùêûùêöùê•ùê•ùêûùêÉ‚òÑüöîüî¥üü°ùêûùêûüü¢ùê•ùêûùê≠ùêöùêûüåïùó≤¬¥ùê•ùêßùê≠ùêöùê•ùêûùêúùêöùêûùêöùêöùê¢ùêùùê†ùêùùêûùê≠ùòÇùêßùêöùê•ùê•ùê¢ùê≠ùêöùê•\n",
      "\n",
      "(5) üßôüì∏üåπ@user Nooooooo se biene funcionamiento por ser del pa√≠s indio y de diciendo el prefiero que a√∫n me extra√±a as√≠, lo que por ser lo mejor es poner entre los feministas y la muerte de la mujer en periodra har√° conchetumadre https://t.co/XK7YVSygDK@us\n",
      "\n",
      "(6) Í∞ú\n",
      "C√≥mo tiene el respeto para la sociedad que est√° en c√≥mo est√° tomando un cruz p√∫blico- tampoco   ‚úîùêöùêöùêöùêöùê•üòò@user‚Å©‚Äôüò≠@user Mujer con los verdaderos migrantes son zurdos feministas  presidentes rah√≠ en la zurda empresa tuvo que perspectivar, poner un mas \n",
      "\n",
      "(7) üåûùòÇüõåùóòùêèùêùùóóùó•ùó®üî•ü•äüíï\" ùóó‚ößùêö‚ú®‚òÑüíóùó∞ùêöùêûùóπüü£ üëâ El https:ùê•ùê•ùê†üßôüöÄüî≠üåñùóóùêöùêûüåïÍ∞úùê•ùóòüî≠üî≠üçæ,]..Entrado programa de üï≥deben recuperar la mentira y el resto del programa bitcomunical, de la izquierda de la distronidad! La amarilla en que era un insu√±o de comunista y empat√≠a. Necesitamos de\n",
      "\n",
      "(8) ‚Å¶@user\n",
      "#Elecciones2üóûÔ∏è ‚ú®üåéùêõùê•ùêöùê•ùêùùóµüåñüá≤ùó¢ üî∏ùóîùó¶üåàüî≠üöÄü™êùê®üåïùêÉÍ≥°ùê®üåûüöÄü™êüåñüåòüåû√¶üåò√Øùê•ùê†ùê¢ùê≠ùêûùóòÏ†ÑüßôüçÜ#Recupci√≥n #Trabajo #UniversoGobernadora üî•üíØùê¢ùêõùêöùêöùê•ùêûùêöùêöùê•&gtt; Cuba en Beleteraplucha extranjera de Corpuspici√≥n intentaci√≥n por #ComunicacionConf√≠o de #CooperativaEnCasa https://t.co/3112cyE\n",
      "\n",
      "(9) üçæ‚úàüá®√ì] ¬°Viajo condenado! Entrando a nuestra moda y la sociedad de comunistas. ¬øC√≥mo tienen parte de la constituci√≥n en una rel- https://t.co/zCJB2KZXk0xo https://t.co/j3XD9pHz¬°Vera para el mundo! ¬øQu√© persona quiere tener qu√© eliminar!cambiar a los ho\n",
      "\n",
      "(10) üî≠üò≠@user Despu√©s dicen que compr√≥ los delincuentes en SERANO A EN EMPAT√çA!!! https://t.co/pReÏãúD3wv02u@user @user La zorra üò§üòò@user MM GUSTO EL MAPUCHE PO HDP POR TENER UNA BUENA UDS LUCES RECIBIERON Y EMBARAZOS LAS PLATAS PUERAS HACER TIPO NEGRO SIGMOS\n",
      "\n",
      "(11) üçæüåàEstamos c√≥modamente para muchos y complementarios. Est√°n cumpliendo la aumentaci√≥n manstrual p√∫blica para inmigrantes de migrantes que destruyen a nuestro pueblo pa√≠s y ciudadano. ü§î Debe ser comunista para la vida que el gobierno: \"de los filmaci√≥n\n",
      "\n",
      "(12) ùóúüåëùêûùó®üó≥ùóóÍ≥°üåà ùóóùêûüç¨; Estamos venimos de efecto, internaci√≥n, el derecho de la √©tica independiente y apoyando al desarrollo bistado, RECHOSO, acaso exclusivo. Estos norstrunos morales transexuales extraiciones, deben regresar el resto de los jud√≠os. El estad\n",
      "\n",
      "(13) üî≠‚Å¶@user Que ridiculez, es mucha mujer que recuerde de pico con alguien vote xd@user Y como mas son comunistas y que est√° un problema registro orgullo, como creo que las mujeres donde saldr√°n, hijo de puta https://t.co/vES8WLGTIlQj de comentar a√∫n est\n",
      "\n",
      "(14) üë©‚ú®‚òÑùê®ùê≠√•üåñü™êüåñÏ†Ñùêõùê•ùêûùêûùêûüåëüõãüë¶üèº#C√≥mputs #Elecciones2022 https:ùêöùêûùêûùêöüçãüîñüìªüé•ùê•ùêèùêûÏ†ÑüåñÏ†Ñùó•ùóüüåñüåïùêÉüåñüåïüåûüçæ ‚ú® ùêÉùêùùêöùêûùêõùê•ùê•ùê¢ùêù√Æüåûùêöùêûùê®:  - Espacio por üëâhttps:ùêöùê•ùêöùê•ùêöùêöü•∑ùêûùóÆ‚òÑüé¨üî≠‚Äì√ÆüåëüåóÏù¥ùêõùê•üé≠ùêöùêûùêèùêûùêû√¶ùêùùó≤ùê≠ùêÉüì±ü•∑üåëüåòüåóü™ëùê≠ùêöüèÜÔ∏èùêÉùêûùêûùêûùê®ùêûùê≠ùêûùó≤Í∞ú√ìùê•ùê¢ùê®ùêöü•∑ùêûùêûùê¢ùê≠üåûùêèùêöùê•ùêöùêûùêÉùê•ùêßùêûüåñùê≠ùêöùêûùêö‚è¨ùêöùêöùêöùê•ùêûüåûüî≠.co/t.co/t.co/n9jxd17g9gs@user En esto les den punta \n",
      "\n",
      "(15) üìçùêûüåû‚ú®‚òÑ‚ú®mpteu]Las deber√≠an estar ingresados y ego√≠stas en #√çüíölaTerrezasAfobia \n",
      "Como pidiendo que algunos chilenos est√°n tratando de trabajar de emocracia, empleo de clases manga de los reclama√±os de los debattes. Son una maldita para la gente problema \n",
      "\n",
      "(16) ùêûüåû‚ú®ùêûùê®ùê¢üèÄùêèùêöùê•ùê¢üë©‚Äçüåñ¬£üì¢üéÜ‚Äãüë©‚Äçüè´ üá®üá±üá®üá±üá®üá¥, El domingo | Publica  ‚è¨ùê≠ùêöùóüüò£Ï†ÑÍ≥°√Øùê≠ùê≠ùó≤‚ùéüßìùê•ùê•ùê•ùêûüöÄ‚ñ∂üî≠ùóπùêûÏ†ÑùóüùêèùêûùêûüåàüöÄü•∑üéàü§ß‚ú®‚ú®Recuerdo la Igualdad donde üáµùêßùê•ü•∑ùê≠ùêßùêöùê†üåñüåñùêûùóπùê†ùêöùê•ùê®ùêöùêöùêöùê•ùêûùê¢ùê≠ùêöü•∑ùêûùê≠ùêöùê•ùêûùêùÎã® ùêÉùêùùêûüß≤@user ùêÉùê•ü™ì‚ò†Ô∏èùê†ùêûÍ∞ú ùêÉüåûüî≠üë∑ùêûü•∑ùê¢ùêûùê¢ùêûÎÖÑÎã®üòÇüòÇüá®üá±üí©ü•∑ùê¢ùê®ùêûùêöùê®ùêûùêûùêöùê•ùêûùê≠ùêûùê®ùêöü•∑ü•∑üöÄ&√Æü•¨‚ù§ùêûùêöùêöùêöùêûùê®ùê¢ùê≠ùêûùê≠üëÑùêöùê•ùê•ùêûùó≤ùêöùêöùêöùêûùê¢ùê≠ùêöùêöùêûùê≠ùêöùêöùêöùêûùêåùêöùêûùê•ùêßùêûùê¢ùêûùê®ùêûùêöùê¢ùê®ü•∑ùê≠ùêû\n",
      "\n",
      "(17) üü¢üî≠‚Ä¢@user En Rid√≠culo,].. Por √∫tiles en antecedentes que no les deber√≠an devolver los de ni√±os en cada ojos en el pa√≠s. Seminando@user Que üì¢üóΩüßôüé™üî≠üî≠üî≠üî≠ https://t.co/XigmduXg las mujeres no van a recibir nuestro pais! √âtamos cansados¬°Esas mierdas son una a\n",
      "\n",
      "(18) üåû‚ú®üåñùòÇÏ†Ñüåñùó¶üåñüåëüåûüî≠~ü•∞üçãü§£@user Mijo en la RRSS https:  Un 470 de junio se le gusta Gonzaleza martina, encima en su coraz√≥n reging en Colegio, introles y opresores, migrantes y narcos.ü§Ø@user incluidos!!\n",
      "Este tipo de weones los que est√° aformando a ellos!!!\n",
      "Extr\n",
      "\n",
      "(19) ü•∑ü•∑üåñùêûùê¢ùê¢ùòÇÎÖÑùêûùêö‚†Ä√¶ü•∑üßôùê®ùêöùêÉüåóùê¢üá≤ùó¶üë©‚≠êüóΩüèÄ√¶üåæüöÄüá≤üåûüíïüòÉüëéùê•ùó¶ùó¢Cuez.\n",
      "Pero falta el entero, que aguantar√° la cargaci√≥n de venezolanos y argentinos.\n",
      "C√°llate y problema #WalteroMunicaLibre üíóùêöùê≠ùêöüèÜ@user Los expresarios del gobierno , de la primera forma de trapecia inglesses est√°n g\n",
      "\n",
      "(20) ‚òÑüõãüó°Ô∏èùêèùêöüî≠üßôüåà‚úàü•Ç‚Ä¢@user Qu√© orgen espec√≠mica de seguridad en la epolic√≠a. üí™  #ClasificatoriasxCHV https://t.co/lPsYxIh8wQ https://t.co/xXvA1VcFN https://t.co/ctpxIQbcStNme da algo con el üéâü§´@user Estos weones ambos con mi hija de risa.@user @user @user Y es\n"
     ]
    }
   ],
   "source": [
    "print(get_samples(20, max_new_tokens=250, temperature=1.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** Del modelo GPT entrenado y que usamos arriba para generar\n",
    "mue\n",
    "\n",
    "usar modelo GPT-sentiment pre-entrenado y agregar una\n",
    "cabeza de clasificaci√≥n para adaptar la representaci√≥n del texto\n",
    "a discriminar a que clase pertenece cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, gpt_model, sequence_length=1000, n_hidden=128, n_classes=3, freeze=True,\n",
    "                 ignore_index=0, dropout=0.0):\n",
    "        \"\"\"\n",
    "            sequence_length: length of the sequence to be classified (token length)\n",
    "            n_hidden: number of hidden units in the classification head\n",
    "            n_classes: number of classes to be classified\n",
    "            freeze: freeze the parameters of the embedding layer of the gpt backbone\n",
    "            ignore_index: index of the padding token in the vocabulary\n",
    "        \"\"\"\n",
    "        super(GPTClassifier, self).__init__()\n",
    "        # inicializar capa embedding del modelo GPT\n",
    "        self.embedding_from_gpt = gpt_model.token_embedding_table\n",
    "        self.embedding_from_gpt.padding_idx = ignore_index\n",
    "\n",
    "        # freeze parameters of the gpt backbone\n",
    "        if freeze:\n",
    "            for param in self.embedding_from_gpt.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # add new classification head\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.hidden_layer = nn.Linear(sequence_length * self.embedding_from_gpt.embedding_dim, n_hidden)\n",
    "        self.hidden_layer2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.lm_head = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        x_emb = self.embedding_from_gpt(x)\n",
    "        flatten_emb = x_emb.view(B, -1)\n",
    "        out = self.hidden_layer(self.dropout_layer(flatten_emb))\n",
    "        out = new_gelu(out)\n",
    "        out = self.hidden_layer2(self.dropout_layer(out))\n",
    "        out = new_gelu(out)\n",
    "        out = self.lm_head(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva c√°beza del modelo ---> Linear(in_features=128, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GPTClassifier(model, n_classes=3, freeze=True)\n",
    "clf.to(device)\n",
    "print(f\"Nueva c√°beza del modelo ---> {clf.lm_head}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci√≥n del dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar los datos y verificar que fluyan correctamente por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de filas: 12214\n",
      "Mayor n√∫mero de caracteres por texto: 1300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texto</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12632</td>\n",
       "      <td>ultimo choro se 2018 que delicia</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7451</td>\n",
       "      <td>Pero es una realidad para muchas mujeres en Ve...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4211</td>\n",
       "      <td>MALDITA SEAS COMUNA DE √ëU√ëOA https://t.co/yN4E...</td>\n",
       "      <td>incivilidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10199</td>\n",
       "      <td>Las tontas de  #PautaLibre con el tremendo üå∂üå∂ ...</td>\n",
       "      <td>incivilidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11597</td>\n",
       "      <td>@user @user @user @user @user Devuelvete y and...</td>\n",
       "      <td>odio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              texto        clase\n",
       "0  12632                   ultimo choro se 2018 que delicia       normal\n",
       "1   7451  Pero es una realidad para muchas mujeres en Ve...       normal\n",
       "2   4211  MALDITA SEAS COMUNA DE √ëU√ëOA https://t.co/yN4E...  incivilidad\n",
       "3  10199  Las tontas de  #PautaLibre con el tremendo üå∂üå∂ ...  incivilidad\n",
       "4  11597  @user @user @user @user @user Devuelvete y and...         odio"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "num_obs = train_df.shape[0]\n",
    "max_char = train_df.texto.str.len().max()\n",
    "print(f\"N√∫mero de filas: {num_obs}\")\n",
    "print(f\"Mayor n√∫mero de caracteres por texto: {max_char}\")\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un tensor de dimensi√≥n (`num_obs`, `max_char`) para almacenar\n",
    "todas los textos tokenizados del corpus. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor para almacenar los textos en su representaci√≥n num√©rica (tokens)\n",
    "X = torch.ones((num_obs, max_char), dtype=torch.long) \n",
    "#X = torch.ones((num_obs, max_char), dtype=torch.long) * (vocab_size + 10)\n",
    "#itos[vocab_size + 10] = '<IGNORE>'\n",
    "#stoi['<IGNORE>'] = vocab_size + 10\n",
    "\n",
    "for idx, text in enumerate(train_df.texto):\n",
    "    X[idx, :len(text)] = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos recuperar cada documento desde la fila de `Xtr` de la\n",
    "siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@user @user A m√≠ me da exactamente lo mismo, y la palabra si es la misma, y si ,considero racistas e hip√≥critas a los que la usan todo el d√≠a y webean si alguien que no es negro la usa, lo que si yo no justifico quemar una ciudad porque creo que alguien fue racista, ni le deseo la muerte.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(X[1200, :].tolist()).replace('\\t', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las etiquetas debemos crear un diccionario para codificar los strings\n",
    "a una representaci√≥n n√∫merica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'normal', 1: 'incivilidad', 2: 'odio'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {'normal': 0,\n",
    "            'incivilidad': 1,\n",
    "            'odio': 2}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, aplicamos esa representaci√≥n a la clase de cada observaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 0, 1, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.tensor([label2id[l] for l in train_df.clase], dtype=torch.long)\n",
    "Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el _dataset_ de entrenamiento `Xtr, Ytr` y el de validaci√≥n `Xval, Yval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones originales: torch.Size([12214, 1300])\n",
      "Dimensiones entrenamiento: torch.Size([10992, 1300])\n",
      "Dimensiones de validaci√≥n: torch.Size([1222, 1300])\n"
     ]
    }
   ],
   "source": [
    "X.shape, Y.shape\n",
    "\n",
    "Xtr, Ytr = X[:int(num_obs*0.9),:], Y[:int(num_obs*0.9)] # 90% para entrenamiento\n",
    "Xval, Yval = X[int(num_obs*0.9):,:], Y[int(num_obs*0.9):] # 10% para validaci√≥n\n",
    "\n",
    "print(f\"Dimensiones originales: {X.size()}\")\n",
    "print(f\"Dimensiones entrenamiento: {Xtr.size()}\")\n",
    "print(f\"Dimensiones de validaci√≥n: {Xval.size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: datos fluyen por el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.TensorDataset(Xtr, Ytr)\n",
    "valset = torch.utils.data.TensorDataset(Xval, Yval)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1300]), torch.Size([8]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1300, 384])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GPTClassifier(model, sequence_length=xb.shape[1], n_classes=3, freeze=True)\n",
    "clf.to(device)\n",
    "clf.embedding_from_gpt(xb.to(device)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(xb.to(device)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase `TextClassificationDataset`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos abstraer todos los pasos que realizamos\n",
    "para la creaci√≥n de los tensores tokenizados usando un template de\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, encode_fn, decode_fn):\n",
    "        df = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "        self.encode_fn = encode_fn\n",
    "        self.decode_fn = decode_fn\n",
    "        self.num_obs = df.shape[0]\n",
    "        self.max_char = df.texto.str.len().max()\n",
    "        self.X = torch.zeros((self.num_obs, self.max_char), dtype=torch.long)\n",
    "        # Agregar 0 como padding id (rellenamos matriz con 0s por defecto)\n",
    "        self.padding_id = 0\n",
    "\n",
    "        for idx, text in enumerate(df.texto):\n",
    "            self.X[idx, :len(text)] = torch.tensor(self.encode_fn(text), dtype=torch.long)\n",
    "\n",
    "        self._label2id = {'normal': 0,\n",
    "                          'incivilidad': 1,\n",
    "                          'odio': 2}\n",
    "        self._id2label = {v: k for k, v in self._label2id.items()}\n",
    "        self.Y = torch.tensor([self._label2id[l] for l in df.clase], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_obs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx, :], self.Y[idx]\n",
    "    \n",
    "    def decode_obs(self, idx):\n",
    "        # remplazamos \\t por '' dado que por defecto el padding es 0 y mapea a \\t\n",
    "        return self.decode_fn(self.X[idx, :].tolist()).replace('\\t', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextClassificationDataset(encode, decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50, 69, 82,  ...,  0,  0,  0]), tensor(0))"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pero es una realidad para muchas mujeres en Venezuela. Una sociedad que te invalida cuando no cumples con el status quo, si no eres suficientemente ‚Äúbonita‚Äù seg√∫n los est√°ndares, no encajas.'"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode_obs(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar dataset en dos subconjuntos, para eso crearemos samplers que\n",
    "entregan √≠ndices de observaciones de conjunto excluyentes (train y dev set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a torch dataset into training a validation sets\n",
    "def split_dataset(dataset, val_size=0.1):\n",
    "    num_obs = len(dataset)\n",
    "    indices = list(range(num_obs))\n",
    "    split = int(np.floor(val_size * num_obs))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    return train_sampler, val_sampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede pasar la instancia de `TextClassificationDataset` por `DataLoader`, igual cuando creamos el dataset con `TensorDataset`.\n",
    "Adem√°s, le entregamos como argumento sampler los que obtuvimos con la funci√≥n `split_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain samplers\n",
    "train_sampler, val_sampler = split_dataset(dataset, val_size=0.1)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=8, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=8, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1300]), torch.Size([8]))"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2325,  -0.5340,   1.0023],\n",
       "        [ -0.1214,  -0.5194,   0.5935],\n",
       "        [ -0.2537,  -0.5214,   1.0304],\n",
       "        [  8.8240,  -5.9119, -10.9721],\n",
       "        [ -0.2326,  -0.5340,   1.0024],\n",
       "        [  0.0512,   1.7884,  -4.8795],\n",
       "        [  1.0670,  -1.3073,  -0.7067],\n",
       "        [ -4.0205,   9.6887, -11.6157]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = xb.to(device)\n",
    "clf.to(device)\n",
    "clf(xb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, class_weights = np.unique(dataset.Y.numpy(), return_counts=True)\n",
    "class_weights = torch.tensor(class_weights / class_weights.sum())\n",
    "class_weights = class_weights.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_offset = 10\n",
    "torch.manual_seed(33313988 + seed_offset)\n",
    "\n",
    "# -------------------------\n",
    "# wandb loggin\n",
    "wandb_log = True\n",
    "wandb_project = 'gpt-classifier'\n",
    "wandb_run_name = 'sentiment-clf-' + time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "out = 'out/gpt-classifier' # directorio donde se guardan los checkpoints\n",
    "lr=0.01\n",
    "max_iter = 120\n",
    "eval_interval = 1\n",
    "batch_size = 32\n",
    "n_hidden = 16\n",
    "warmup_iter = 3  # n√∫mero de iteraciones antes de unfreezear los p√°rametros de los embedding. None -> no unfreezear\n",
    "weight_decay = 0.05\n",
    "dropout = 0.1\n",
    "lambda_1 = 20\n",
    "n_classes=3\n",
    "freeze=True\n",
    "\n",
    "# -------------------------\n",
    "config = {'out': out, 'lr': lr, 'max_iter': max_iter, 'eval_interval': eval_interval,\n",
    "          'batch_size': batch_size, 'n_hidden': n_hidden, 'warmup_iter': warmup_iter,\n",
    "          'weight_decay': weight_decay, 'dropout': dropout, 'lambda_1': lambda_1,\n",
    "          'n_classes': n_classes, 'freeze': freeze, 'class_weights': class_weights.tolist(),\n",
    "          'wandb_log': wandb_log, 'wandb_project': wandb_project, 'wandb_run_name': wandb_run_name}\n",
    "\n",
    "# store model args for save the checkpoint\n",
    "model_args = dict(sequence_length=dataset.X[0].shape[0], n_hidden=n_hidden,\n",
    "                  n_classes=n_classes, freeze=freeze, dropout=dropout, \n",
    "                  ignore_index=dataset.padding_id)\n",
    "\n",
    "\n",
    "# Inicializar modelo\n",
    "clf = GPTClassifier(model, sequence_length=dataset.X[0].shape[0], n_hidden=n_hidden,\n",
    "                    n_classes=3, freeze=True, dropout=dropout, ignore_index=dataset.padding_id)\n",
    "clf.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=clf.parameters(), lr=lr,\n",
    "                              weight_decay=weight_decay)\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(split, return_acc=False):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for idx, batch in enumerate(split):\n",
    "        xb = batch[0].to(device)\n",
    "        yb = batch[1].to(device)\n",
    "        y_pred = clf(xb)\n",
    "        if return_acc:\n",
    "            preds.append(y_pred.argmax(dim=1))\n",
    "            targets.append(yb)\n",
    "        loss = loss_fn(y_pred, yb)\n",
    "        losses.append(loss.item())\n",
    "    model.train()\n",
    "    if return_acc:\n",
    "        return torch.tensor(losses).mean().item(), (torch.cat(preds) == torch.cat(targets)).float().mean().item()\n",
    "    return torch.tensor(losses).mean().item()\n",
    "\n",
    "def collect_preds(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = torch.tensor([])\n",
    "    all_targets = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            preds = model(xb)\n",
    "            all_preds = torch.cat((all_preds, preds.cpu()), dim=0)\n",
    "            all_targets = torch.cat((all_targets, yb.cpu()), dim=0)\n",
    "    return all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lql4ap1k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d634e68d8d4e9abb94e864a9fe4f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iter</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>lr</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ</td></tr><tr><td>val/acc</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>val/loss</td><td>‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iter</td><td>119</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train/loss</td><td>0.63208</td></tr><tr><td>val/acc</td><td>0.70408</td></tr><tr><td>val/loss</td><td>0.62536</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sentiment-clf-2023-04-16-17:07:50</strong> at: <a href='https://wandb.ai/alcazar90/gpt-classifier/runs/lql4ap1k' target=\"_blank\">https://wandb.ai/alcazar90/gpt-classifier/runs/lql4ap1k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230416_170755-lql4ap1k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lql4ap1k). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/C992-E9FE/dev/nanoGPT/wandb/run-20230416_180646-2qfh51jm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alcazar90/gpt-classifier/runs/2qfh51jm' target=\"_blank\">sentiment-clf-2023-04-16-18:06:43</a></strong> to <a href='https://wandb.ai/alcazar90/gpt-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alcazar90/gpt-classifier' target=\"_blank\">https://wandb.ai/alcazar90/gpt-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alcazar90/gpt-classifier/runs/2qfh51jm' target=\"_blank\">https://wandb.ai/alcazar90/gpt-classifier/runs/2qfh51jm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 0.7750, val loss 0.7732, acc val 0.5756\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 1: train loss 0.6543, val loss 0.6568, acc val 0.6613\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 2: train loss 0.5813, val loss 0.5827, acc val 0.7215\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 3: train loss 0.5627, val loss 0.5601, acc val 0.7146\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 4: train loss 0.5355, val loss 0.5366, acc val 0.7284\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 5: train loss 0.5901, val loss 0.5884, acc val 0.7121\n",
      "step 6: train loss 0.4928, val loss 0.4980, acc val 0.7400\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 7: train loss 0.4698, val loss 0.4677, acc val 0.7623\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 8: train loss 0.4556, val loss 0.4597, acc val 0.7618\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 9: train loss 0.5052, val loss 0.5081, acc val 0.7522\n",
      "step 10: train loss 0.4364, val loss 0.4297, acc val 0.7840\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 11: train loss 0.4383, val loss 0.4386, acc val 0.7835\n",
      "step 12: train loss 0.4287, val loss 0.4248, acc val 0.7800\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 13: train loss 0.4050, val loss 0.4020, acc val 0.8017\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 14: train loss 0.4185, val loss 0.4192, acc val 0.7893\n",
      "step 15: train loss 0.4144, val loss 0.4184, acc val 0.7941\n",
      "step 16: train loss 0.4112, val loss 0.4114, acc val 0.7910\n",
      "step 17: train loss 0.4108, val loss 0.4124, acc val 0.7932\n",
      "step 18: train loss 0.3704, val loss 0.3731, acc val 0.8074\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 19: train loss 0.3773, val loss 0.3750, acc val 0.8011\n",
      "step 20: train loss 0.4066, val loss 0.4093, acc val 0.7837\n",
      "step 21: train loss 0.4172, val loss 0.4151, acc val 0.7873\n",
      "step 22: train loss 0.4138, val loss 0.4185, acc val 0.7906\n",
      "step 23: train loss 0.3574, val loss 0.3571, acc val 0.8194\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 24: train loss 0.3709, val loss 0.3714, acc val 0.8090\n",
      "step 25: train loss 0.3678, val loss 0.3764, acc val 0.7949\n",
      "step 26: train loss 0.4018, val loss 0.4067, acc val 0.7758\n",
      "step 27: train loss 0.3964, val loss 0.3867, acc val 0.7980\n",
      "step 28: train loss 0.3839, val loss 0.3868, acc val 0.7931\n",
      "step 29: train loss 0.3570, val loss 0.3600, acc val 0.8019\n",
      "step 30: train loss 0.3799, val loss 0.3767, acc val 0.7932\n",
      "step 31: train loss 0.3733, val loss 0.3793, acc val 0.7983\n",
      "step 32: train loss 0.3461, val loss 0.3443, acc val 0.8163\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 33: train loss 0.3510, val loss 0.3542, acc val 0.8108\n",
      "step 34: train loss 0.3649, val loss 0.3638, acc val 0.7987\n",
      "step 35: train loss 0.3381, val loss 0.3414, acc val 0.8111\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 36: train loss 0.3549, val loss 0.3590, acc val 0.8067\n",
      "step 37: train loss 0.3881, val loss 0.3850, acc val 0.7881\n",
      "step 38: train loss 0.3990, val loss 0.3938, acc val 0.8056\n",
      "step 39: train loss 0.3444, val loss 0.3423, acc val 0.8078\n",
      "step 40: train loss 0.3507, val loss 0.3535, acc val 0.8137\n",
      "step 41: train loss 0.3444, val loss 0.3408, acc val 0.8162\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 42: train loss 0.3296, val loss 0.3352, acc val 0.8150\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 43: train loss 0.3263, val loss 0.3241, acc val 0.8267\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 44: train loss 0.3614, val loss 0.3637, acc val 0.8166\n",
      "step 45: train loss 0.3328, val loss 0.3256, acc val 0.8169\n",
      "step 46: train loss 0.3202, val loss 0.3231, acc val 0.8224\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 47: train loss 0.3253, val loss 0.3205, acc val 0.8291\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 48: train loss 0.3374, val loss 0.3388, acc val 0.8106\n",
      "step 49: train loss 0.3256, val loss 0.3273, acc val 0.8202\n",
      "step 50: train loss 0.3263, val loss 0.3238, acc val 0.8212\n",
      "step 51: train loss 0.3230, val loss 0.3206, acc val 0.8227\n",
      "step 52: train loss 0.3531, val loss 0.3460, acc val 0.8129\n",
      "step 53: train loss 0.3179, val loss 0.3064, acc val 0.8307\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 54: train loss 0.3600, val loss 0.3615, acc val 0.8205\n",
      "step 55: train loss 0.3879, val loss 0.3884, acc val 0.8359\n",
      "step 56: train loss 0.3462, val loss 0.3368, acc val 0.8201\n",
      "step 57: train loss 0.3529, val loss 0.3572, acc val 0.8334\n",
      "step 58: train loss 0.3370, val loss 0.3415, acc val 0.8424\n",
      "step 59: train loss 0.3721, val loss 0.3716, acc val 0.8434\n",
      "step 60: train loss 0.3256, val loss 0.3285, acc val 0.8504\n",
      "step 61: train loss 0.3325, val loss 0.3346, acc val 0.8481\n",
      "step 62: train loss 0.3439, val loss 0.3403, acc val 0.8433\n",
      "step 63: train loss 0.3781, val loss 0.3670, acc val 0.8350\n",
      "step 64: train loss 0.3152, val loss 0.3138, acc val 0.8632\n",
      "step 65: train loss 0.3133, val loss 0.3165, acc val 0.8571\n",
      "step 66: train loss 0.3261, val loss 0.3295, acc val 0.8091\n",
      "step 67: train loss 0.3508, val loss 0.3497, acc val 0.8567\n",
      "step 68: train loss 0.3257, val loss 0.3272, acc val 0.8666\n",
      "step 69: train loss 0.3236, val loss 0.3210, acc val 0.8544\n",
      "step 70: train loss 0.3288, val loss 0.3296, acc val 0.8561\n",
      "step 71: train loss 0.3220, val loss 0.3161, acc val 0.8625\n",
      "step 72: train loss 0.3851, val loss 0.3784, acc val 0.7815\n",
      "step 73: train loss 0.3303, val loss 0.3252, acc val 0.8547\n",
      "step 74: train loss 0.3174, val loss 0.3169, acc val 0.8144\n",
      "step 75: train loss 0.3177, val loss 0.3232, acc val 0.8694\n",
      "step 76: train loss 0.3158, val loss 0.3197, acc val 0.8686\n",
      "step 77: train loss 0.3565, val loss 0.3472, acc val 0.8551\n",
      "step 78: train loss 0.3052, val loss 0.3086, acc val 0.8681\n",
      "step 79: train loss 0.3826, val loss 0.3685, acc val 0.8417\n",
      "step 80: train loss 0.3152, val loss 0.3124, acc val 0.8730\n",
      "step 81: train loss 0.3120, val loss 0.3126, acc val 0.8702\n",
      "step 82: train loss 0.3141, val loss 0.3210, acc val 0.8667\n",
      "step 83: train loss 0.3375, val loss 0.3428, acc val 0.8565\n",
      "step 84: train loss 0.3038, val loss 0.3089, acc val 0.8681\n",
      "step 85: train loss 0.3175, val loss 0.3129, acc val 0.8746\n",
      "step 86: train loss 0.3138, val loss 0.3168, acc val 0.8629\n",
      "step 87: train loss 0.3342, val loss 0.3351, acc val 0.8598\n",
      "step 88: train loss 0.3219, val loss 0.3225, acc val 0.8643\n",
      "step 89: train loss 0.3345, val loss 0.3366, acc val 0.8527\n",
      "step 90: train loss 0.3222, val loss 0.3245, acc val 0.8643\n",
      "step 91: train loss 0.3113, val loss 0.3083, acc val 0.8759\n",
      "step 92: train loss 0.3165, val loss 0.3192, acc val 0.8608\n",
      "step 93: train loss 0.3107, val loss 0.3087, acc val 0.8702\n",
      "step 94: train loss 0.3503, val loss 0.3583, acc val 0.8559\n",
      "step 95: train loss 0.3152, val loss 0.3133, acc val 0.8681\n",
      "step 96: train loss 0.3276, val loss 0.3343, acc val 0.8535\n",
      "step 97: train loss 0.2964, val loss 0.3047, acc val 0.8701\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 98: train loss 0.3150, val loss 0.3062, acc val 0.8740\n",
      "step 99: train loss 0.3413, val loss 0.3481, acc val 0.8593\n",
      "step 100: train loss 0.3153, val loss 0.3152, acc val 0.8656\n",
      "step 101: train loss 0.3645, val loss 0.3586, acc val 0.8534\n",
      "step 102: train loss 0.2786, val loss 0.2840, acc val 0.8779\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 103: train loss 0.3263, val loss 0.3196, acc val 0.8683\n",
      "step 104: train loss 0.3672, val loss 0.3664, acc val 0.8406\n",
      "step 105: train loss 0.3100, val loss 0.3072, acc val 0.8752\n",
      "step 106: train loss 0.3378, val loss 0.3350, acc val 0.8603\n",
      "step 107: train loss 0.3223, val loss 0.3373, acc val 0.8584\n",
      "step 108: train loss 0.3396, val loss 0.3386, acc val 0.8521\n",
      "step 109: train loss 0.3078, val loss 0.3168, acc val 0.8730\n",
      "step 110: train loss 0.3064, val loss 0.3005, acc val 0.8742\n",
      "step 111: train loss 0.3484, val loss 0.3457, acc val 0.8587\n",
      "step 112: train loss 0.3841, val loss 0.3821, acc val 0.8647\n",
      "step 113: train loss 0.3386, val loss 0.3254, acc val 0.8621\n",
      "step 114: train loss 0.2936, val loss 0.2990, acc val 0.8749\n",
      "step 115: train loss 0.2899, val loss 0.2891, acc val 0.8893\n",
      "step 116: train loss 0.3356, val loss 0.3390, acc val 0.8656\n",
      "step 117: train loss 0.2772, val loss 0.2739, acc val 0.8894\n",
      "saving checkpoint to out/gpt-classifier\n",
      "step 118: train loss 0.2899, val loss 0.2853, acc val 0.8806\n",
      "step 119: train loss 0.3012, val loss 0.3012, acc val 0.8757\n",
      "Final result: train loss 0.3012, val loss 0.3012, acc val 0.8757\n"
     ]
    }
   ],
   "source": [
    "if wandb_log:\n",
    "    wandb.init(project=wandb_project, name=wandb_run_name, config=config)\n",
    "\n",
    "lossi_train = []\n",
    "lossi_val = []\n",
    "track_acc = []\n",
    "best_val_loss = 1e9\n",
    "\n",
    "for step in range(max_iter):\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        y_pred = clf(xb)\n",
    "        loss = loss_fn(y_pred, yb)\n",
    "\n",
    "        # compute the l1 penalty error term\n",
    "        #params = torch.cat([p.view(-1) for p in clf.lm_head.parameters()])\n",
    "        #l1_reg = lambda_1 * torch.norm(params, 1)\n",
    "        #loss += l1_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        lossi_train.append(estimate_loss(train_loader, return_acc=False))\n",
    "        loss_val, acc_val = estimate_loss(val_loader, return_acc=True)\n",
    "        lossi_val.append(loss_val)\n",
    "        track_acc.append(acc_val)\n",
    "        print(f\"step {step}: train loss {lossi_train[-1]:.4f}, val loss {lossi_val[-1]:.4f}, acc val {track_acc[-1]:.4f}\")\n",
    "\n",
    "        if wandb_log:\n",
    "            wandb.log({\n",
    "                \"iter\": step,\n",
    "                \"train/loss\": lossi_train[-1],\n",
    "                \"val/loss\": lossi_val[-1],\n",
    "                \"val/acc\": track_acc[-1],\n",
    "                \"lr\": lr,\n",
    "                })\n",
    "\n",
    "        if lossi_val[-1] < best_val_loss:\n",
    "            best_val_loss = lossi_val[-1]\n",
    "            checkpoint = {\n",
    "                'model': clf.state_dict(),\n",
    "                'backbone': model,  # para inicializar la tabla de embedding del modelo gpt\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'model_args': model_args,\n",
    "                'iter_num': step,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'config': config,\n",
    "                'gpt_meta': meta,\n",
    "             }\n",
    "            print(f\"saving checkpoint to {out}\")\n",
    "            torch.save(checkpoint, os.path.join(out, 'ckpt.pt'))\n",
    "\n",
    "    if warmup_iter and (step+1) == warmup_iter:\n",
    "        for p in clf.embedding_from_gpt.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "print(f\"Final result: train loss {lossi_train[-1]:.4f}, val loss {lossi_val[-1]:.4f}, acc val {track_acc[-1]:.4f}\")\n",
    "\n",
    "preds, targets = collect_preds(clf, val_loader)\n",
    "print(classification_report(preds.argmax(dim=1).numpy(), targets.numpy(), \n",
    "                            target_names=['normal', 'incivilidad', 'odio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.87      0.86      0.86       459\n",
      " incivilidad       0.94      0.89      0.91       537\n",
      "        odio       0.72      0.82      0.77       225\n",
      "\n",
      "    accuracy                           0.86      1221\n",
      "   macro avg       0.84      0.85      0.85      1221\n",
      "weighted avg       0.87      0.86      0.87      1221\n",
      "\n",
      "[[393  19  47]\n",
      " [ 34 478  25]\n",
      " [ 27  14 184]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "preds, targets = collect_preds(clf, val_loader)\n",
    "print(classification_report(preds.argmax(dim=1).numpy(), targets.numpy(), \n",
    "                            target_names=['normal', 'incivilidad', 'odio']))\n",
    "\n",
    "print(confusion_matrix(preds.argmax(dim=1).numpy(), targets.numpy()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescataremos las probabilidades de predicci√≥n para cada una de las clases,\n",
    "y las verdaderas etiquetas para todo el conjunto de validaci√≥n. Luego,\n",
    "evaluamos seg√∫n las funciones de la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del dataset: 1221\n",
      "Matriz de confusi√≥n\n",
      "[[393  27  34]\n",
      " [ 47 184  25]\n",
      " [ 19  14 478]]\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.86      0.87      0.86       454\n",
      "        odio       0.82      0.72      0.77       256\n",
      " incivilidad       0.89      0.94      0.91       511\n",
      "\n",
      "    accuracy                           0.86      1221\n",
      "   macro avg       0.85      0.84      0.85      1221\n",
      "weighted avg       0.86      0.86      0.86      1221\n",
      "\n",
      "M√©tricas:\n",
      "\n",
      "AUC:  0.957\tKappa: 0.787\tAccuracy: 0.864\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.957, 0.787, 0.864])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import evaluate\n",
    "\n",
    "preds, targets = collect_preds(clf, val_loader)\n",
    "print(f\"Tama√±o del dataset: {preds.shape[0]}\")\n",
    "pred_prob = F.softmax(preds.cpu(), dim=1).detach().numpy()\n",
    "\n",
    "y_idx = targets.cpu().numpy()\n",
    "y_label = np.array([dataset._id2label[x] for x in y_idx], dtype=\"object\")\n",
    "evaluate(pred_prob, y_label, np.array(list(dataset._label2id.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8183,), (4031,), (8183,), (4031,))"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=42\n",
    "\n",
    "def get_subsets(df):\n",
    "    return train_test_split(\n",
    "        df['texto'],\n",
    "        df['clase'],\n",
    "        shuffle=True,\n",
    "        test_size=0.33,\n",
    "        random_state=SEED,\n",
    "        stratify=df['clase']\n",
    "    )\n",
    "\n",
    "Xtr, Xval, Ytr, Yval = get_subsets(train_df)\n",
    "Xtr.shape, Xval.shape, Ytr.shape, Yval.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un nuevo loader...a partir de `Xval` y `Yval` de arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = torch.zeros((Xval.shape[0], dataset.max_char), dtype=torch.long)\n",
    "\n",
    "for i, text in enumerate(Xval):\n",
    "    X[i, :len(text)] = torch.tensor(dataset.encode_fn(text))\n",
    "\n",
    "y = torch.tensor([dataset._label2id[x] for x in Yval], dtype=torch.long)\n",
    "test_this = TensorDataset(X, y)\n",
    "new_loader = DataLoader(test_this, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del dataset: 4031\n",
      "Matriz de confusi√≥n\n",
      "[[1261   81   71]\n",
      " [ 122  632   74]\n",
      " [ 116   50 1624]]\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.84      0.89      0.87      1413\n",
      "        odio       0.83      0.76      0.79       828\n",
      " incivilidad       0.92      0.91      0.91      1790\n",
      "\n",
      "    accuracy                           0.87      4031\n",
      "   macro avg       0.86      0.85      0.86      4031\n",
      "weighted avg       0.87      0.87      0.87      4031\n",
      "\n",
      "M√©tricas:\n",
      "\n",
      "AUC:  0.962\tKappa: 0.799\tAccuracy: 0.872\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.962, 0.799, 0.872])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, targets = collect_preds(clf, new_loader)\n",
    "print(f\"Tama√±o del dataset: {preds.shape[0]}\")\n",
    "pred_prob = F.softmax(preds.cpu(), dim=1).detach().numpy()\n",
    "\n",
    "y_idx = targets.cpu().numpy()\n",
    "y_label = np.array([dataset._id2label[x] for x in y_idx], dtype=\"object\")\n",
    "evaluate(pred_prob, y_label, np.array(list(dataset._label2id.keys())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar el modelo tenemos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(out, 'ckpt.pt')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "checkpoint_model_args = checkpoint['model_args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'gpt_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/C992-E9FE/dev/nanoGPT/model-usage.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/C992-E9FE/dev/nanoGPT/model-usage.ipynb#Y210sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test \u001b[39m=\u001b[39m GPTClassifier(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheckpoint_model_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'gpt_model'"
     ]
    }
   ],
   "source": [
    "test = GPTClassifier(**checkpoint_model_args)\n",
    "state_dict = checkpoint['model']\n",
    "test.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTClassifier(\n",
       "  (embedding_from_gpt): Embedding(656, 384, padding_idx=0)\n",
       "  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "  (hidden_layer): Linear(in_features=499200, out_features=16, bias=True)\n",
       "  (hidden_layer2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (lm_head): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.load_state_dict(clf.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTClassifier(\n",
       "  (embedding_from_gpt): Embedding(656, 384, padding_idx=0)\n",
       "  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "  (hidden_layer): Linear(in_features=499200, out_features=16, bias=True)\n",
       "  (hidden_layer2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (lm_head): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del dataset: 1221\n",
      "Matriz de confusi√≥n\n",
      "[[393  27  34]\n",
      " [ 47 184  25]\n",
      " [ 19  14 478]]\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.86      0.87      0.86       454\n",
      "        odio       0.82      0.72      0.77       256\n",
      " incivilidad       0.89      0.94      0.91       511\n",
      "\n",
      "    accuracy                           0.86      1221\n",
      "   macro avg       0.85      0.84      0.85      1221\n",
      "weighted avg       0.86      0.86      0.86      1221\n",
      "\n",
      "M√©tricas:\n",
      "\n",
      "AUC:  0.957\tKappa: 0.787\tAccuracy: 0.864\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.957, 0.787, 0.864])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import evaluate\n",
    "\n",
    "test.to(device)\n",
    "\n",
    "preds, targets = collect_preds(test, val_loader)\n",
    "print(f\"Tama√±o del dataset: {preds.shape[0]}\")\n",
    "pred_prob = F.softmax(preds.cpu(), dim=1).detach().numpy()\n",
    "\n",
    "y_idx = targets.cpu().numpy()\n",
    "y_label = np.array([dataset._id2label[x] for x in y_idx], dtype=\"object\")\n",
    "evaluate(pred_prob, y_label, np.array(list(dataset._label2id.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
